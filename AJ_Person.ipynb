{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8566a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb295f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1c9ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"num1.mp4\")\n",
    "model = YOLO(\"yolov8m.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3d4764",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=kEcWUZ8unmc  \n",
    "https://www.youtube.com/watch?app=desktop&v=d1bky80NXeQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b6840",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d44bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e7471d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 18 persons, 5 handbags, 1 chair, 335.0ms\n",
      "Speed: 12.3ms preprocess, 335.0ms inference, 25.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 4 handbags, 1 chair, 48.6ms\n",
      "Speed: 2.5ms preprocess, 48.6ms inference, 26.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 3 handbags, 1 chair, 52.1ms\n",
      "Speed: 2.2ms preprocess, 52.1ms inference, 45.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 handbags, 1 chair, 50.0ms\n",
      "Speed: 2.5ms preprocess, 50.0ms inference, 10.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 handbags, 1 chair, 37.7ms\n",
      "Speed: 2.5ms preprocess, 37.7ms inference, 10.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 handbags, 1 chair, 37.3ms\n",
      "Speed: 2.3ms preprocess, 37.3ms inference, 10.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 4 handbags, 1 chair, 37.6ms\n",
      "Speed: 2.2ms preprocess, 37.6ms inference, 30.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 3 handbags, 1 chair, 40.9ms\n",
      "Speed: 2.4ms preprocess, 40.9ms inference, 13.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 2 handbags, 1 chair, 1 cell phone, 45.8ms\n",
      "Speed: 2.2ms preprocess, 45.8ms inference, 19.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 4 handbags, 1 chair, 54.6ms\n",
      "Speed: 2.2ms preprocess, 54.6ms inference, 26.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 3 handbags, 1 chair, 1 cell phone, 55.3ms\n",
      "Speed: 2.4ms preprocess, 55.3ms inference, 25.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 handbags, 1 chair, 1 tv, 1 cell phone, 61.2ms\n",
      "Speed: 3.6ms preprocess, 61.2ms inference, 44.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 2 handbags, 1 chair, 1 cell phone, 51.4ms\n",
      "Speed: 1.9ms preprocess, 51.4ms inference, 20.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 handbags, 1 chair, 1 cell phone, 52.5ms\n",
      "Speed: 2.4ms preprocess, 52.5ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 handbags, 1 chair, 1 cell phone, 54.8ms\n",
      "Speed: 2.7ms preprocess, 54.8ms inference, 39.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 4 handbags, 1 chair, 1 cell phone, 54.3ms\n",
      "Speed: 2.3ms preprocess, 54.3ms inference, 40.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 4 handbags, 1 chair, 1 cell phone, 89.0ms\n",
      "Speed: 2.3ms preprocess, 89.0ms inference, 39.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 4 handbags, 1 chair, 1 cell phone, 62.8ms\n",
      "Speed: 2.4ms preprocess, 62.8ms inference, 25.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 5 handbags, 1 chair, 1 cell phone, 55.4ms\n",
      "Speed: 2.8ms preprocess, 55.4ms inference, 21.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 5 handbags, 1 chair, 1 cell phone, 55.9ms\n",
      "Speed: 2.8ms preprocess, 55.9ms inference, 22.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 6 handbags, 1 chair, 1 cell phone, 53.7ms\n",
      "Speed: 3.1ms preprocess, 53.7ms inference, 20.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 bench, 5 handbags, 1 chair, 1 tv, 1 cell phone, 53.8ms\n",
      "Speed: 2.4ms preprocess, 53.8ms inference, 20.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bench, 7 handbags, 1 chair, 1 tv, 1 cell phone, 57.1ms\n",
      "Speed: 2.6ms preprocess, 57.1ms inference, 19.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bench, 6 handbags, 1 chair, 1 tv, 1 book, 54.2ms\n",
      "Speed: 2.7ms preprocess, 54.2ms inference, 23.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 15 persons, 1 bench, 5 handbags, 1 chair, 1 book, 59.8ms\n",
      "Speed: 2.3ms preprocess, 59.8ms inference, 25.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 bench, 5 handbags, 1 chair, 53.1ms\n",
      "Speed: 2.4ms preprocess, 53.1ms inference, 23.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 bench, 4 handbags, 1 chair, 1 book, 52.6ms\n",
      "Speed: 2.3ms preprocess, 52.6ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 16 persons, 1 bench, 5 handbags, 1 chair, 1 book, 47.9ms\n",
      "Speed: 2.3ms preprocess, 47.9ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 bench, 6 handbags, 1 chair, 54.9ms\n",
      "Speed: 2.2ms preprocess, 54.9ms inference, 20.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 6 handbags, 1 chair, 57.6ms\n",
      "Speed: 2.2ms preprocess, 57.6ms inference, 23.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 5 handbags, 1 chair, 62.1ms\n",
      "Speed: 2.4ms preprocess, 62.1ms inference, 28.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 5 handbags, 1 chair, 1 cell phone, 66.5ms\n",
      "Speed: 2.4ms preprocess, 66.5ms inference, 46.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 6 handbags, 1 chair, 1 cell phone, 53.4ms\n",
      "Speed: 2.3ms preprocess, 53.4ms inference, 37.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 7 handbags, 1 chair, 1 cell phone, 47.1ms\n",
      "Speed: 2.5ms preprocess, 47.1ms inference, 37.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 5 handbags, 1 chair, 1 cell phone, 45.3ms\n",
      "Speed: 2.1ms preprocess, 45.3ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 bench, 8 handbags, 1 chair, 1 cell phone, 53.8ms\n",
      "Speed: 2.3ms preprocess, 53.8ms inference, 40.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 6 handbags, 1 chair, 46.4ms\n",
      "Speed: 2.2ms preprocess, 46.4ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 6 handbags, 1 chair, 46.5ms\n",
      "Speed: 2.5ms preprocess, 46.5ms inference, 20.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 5 handbags, 1 chair, 1 cell phone, 49.6ms\n",
      "Speed: 2.1ms preprocess, 49.6ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 4 handbags, 1 chair, 48.9ms\n",
      "Speed: 2.2ms preprocess, 48.9ms inference, 21.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 5 handbags, 1 chair, 47.4ms\n",
      "Speed: 2.2ms preprocess, 47.4ms inference, 21.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 6 handbags, 1 chair, 46.2ms\n",
      "Speed: 2.4ms preprocess, 46.2ms inference, 19.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 5 handbags, 1 chair, 45.3ms\n",
      "Speed: 2.2ms preprocess, 45.3ms inference, 20.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 5 handbags, 1 chair, 46.3ms\n",
      "Speed: 2.2ms preprocess, 46.3ms inference, 20.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 7 handbags, 1 chair, 1 book, 48.4ms\n",
      "Speed: 2.1ms preprocess, 48.4ms inference, 39.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 6 handbags, 1 chair, 1 cell phone, 1 book, 43.1ms\n",
      "Speed: 2.1ms preprocess, 43.1ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 6 handbags, 1 chair, 1 cell phone, 1 book, 43.8ms\n",
      "Speed: 2.1ms preprocess, 43.8ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 6 handbags, 1 chair, 1 cell phone, 1 book, 47.4ms\n",
      "Speed: 2.2ms preprocess, 47.4ms inference, 22.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 6 handbags, 1 chair, 1 cell phone, 2 books, 50.9ms\n",
      "Speed: 2.1ms preprocess, 50.9ms inference, 40.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 6 handbags, 1 chair, 1 book, 42.4ms\n",
      "Speed: 2.0ms preprocess, 42.4ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 6 handbags, 1 chair, 43.0ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Speed: 2.3ms preprocess, 43.0ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 handbags, 1 chair, 44.1ms\n",
      "Speed: 2.2ms preprocess, 44.1ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 5 handbags, 1 tie, 1 chair, 1 book, 44.6ms\n",
      "Speed: 2.1ms preprocess, 44.6ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 5 handbags, 1 chair, 1 book, 45.9ms\n",
      "Speed: 2.2ms preprocess, 45.9ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 5 handbags, 1 chair, 45.5ms\n",
      "Speed: 2.2ms preprocess, 45.5ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people_bbox: [18, 17, 16, 17, 18, 18, 16, 18, 16, 17, 17, 18, 20, 19, 20, 19, 18, 18, 19, 17, 17, 17, 15, 15, 15, 17, 16, 16, 17, 18, 18, 19, 19, 20, 20, 21, 18, 18, 19, 18, 20, 20, 19, 18, 19, 20, 21, 21, 21, 20, 20, 20, 19, 19, 19]\n",
      "Last People: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 20 persons, 5 handbags, 1 chair, 59.1ms\n",
      "Speed: 4.9ms preprocess, 59.1ms inference, 7.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 5 handbags, 1 chair, 42.5ms\n",
      "Speed: 2.5ms preprocess, 42.5ms inference, 15.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 5 handbags, 1 chair, 60.2ms\n",
      "Speed: 3.0ms preprocess, 60.2ms inference, 15.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 5 handbags, 1 chair, 67.1ms\n",
      "Speed: 4.5ms preprocess, 67.1ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 6 handbags, 1 chair, 47.8ms\n",
      "Speed: 3.9ms preprocess, 47.8ms inference, 12.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 5 handbags, 1 chair, 41.1ms\n",
      "Speed: 2.4ms preprocess, 41.1ms inference, 15.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 5 handbags, 1 chair, 40.9ms\n",
      "Speed: 2.5ms preprocess, 40.9ms inference, 14.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 5 handbags, 1 chair, 41.2ms\n",
      "Speed: 2.3ms preprocess, 41.2ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 4 handbags, 1 chair, 42.3ms\n",
      "Speed: 2.2ms preprocess, 42.3ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 4 handbags, 1 chair, 42.7ms\n",
      "Speed: 2.1ms preprocess, 42.7ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 handbags, 1 chair, 43.6ms\n",
      "Speed: 2.1ms preprocess, 43.6ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 handbags, 1 chair, 44.8ms\n",
      "Speed: 2.3ms preprocess, 44.8ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 4 handbags, 1 chair, 43.4ms\n",
      "Speed: 2.2ms preprocess, 43.4ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 3 handbags, 1 chair, 44.9ms\n",
      "Speed: 2.2ms preprocess, 44.9ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 handbags, 1 chair, 1 cell phone, 43.7ms\n",
      "Speed: 2.2ms preprocess, 43.7ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 5 handbags, 1 chair, 1 cell phone, 43.8ms\n",
      "Speed: 2.2ms preprocess, 43.8ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 bench, 5 handbags, 1 chair, 1 cell phone, 43.1ms\n",
      "Speed: 2.1ms preprocess, 43.1ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 1 bench, 4 handbags, 1 chair, 1 cell phone, 43.0ms\n",
      "Speed: 2.2ms preprocess, 43.0ms inference, 17.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 6 handbags, 1 chair, 1 cell phone, 42.8ms\n",
      "Speed: 2.3ms preprocess, 42.8ms inference, 19.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 4 handbags, 1 chair, 1 cell phone, 43.0ms\n",
      "Speed: 2.2ms preprocess, 43.0ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 5 handbags, 1 chair, 1 cell phone, 43.5ms\n",
      "Speed: 2.1ms preprocess, 43.5ms inference, 17.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 5 handbags, 1 chair, 43.8ms\n",
      "Speed: 2.3ms preprocess, 43.8ms inference, 17.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 5 handbags, 1 chair, 44.8ms\n",
      "Speed: 2.3ms preprocess, 44.8ms inference, 18.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 5 handbags, 1 chair, 46.1ms\n",
      "Speed: 2.4ms preprocess, 46.1ms inference, 19.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 4 handbags, 1 chair, 46.0ms\n",
      "Speed: 2.3ms preprocess, 46.0ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 4 handbags, 1 chair, 44.8ms\n",
      "Speed: 2.1ms preprocess, 44.8ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 5 handbags, 1 chair, 44.7ms\n",
      "Speed: 2.2ms preprocess, 44.7ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 5 handbags, 1 chair, 44.4ms\n",
      "Speed: 2.5ms preprocess, 44.4ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 4 handbags, 1 chair, 44.1ms\n",
      "Speed: 2.0ms preprocess, 44.1ms inference, 16.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 4 handbags, 1 chair, 44.9ms\n",
      "Speed: 2.3ms preprocess, 44.9ms inference, 18.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 4 handbags, 1 chair, 43.8ms\n",
      "Speed: 2.2ms preprocess, 43.8ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 train, 1 bench, 4 handbags, 1 chair, 43.9ms\n",
      "Speed: 2.5ms preprocess, 43.9ms inference, 18.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 train, 1 bench, 4 handbags, 1 chair, 43.7ms\n",
      "Speed: 2.2ms preprocess, 43.7ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 train, 5 handbags, 1 chair, 43.5ms\n",
      "Speed: 2.3ms preprocess, 43.5ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 5 handbags, 1 chair, 43.0ms\n",
      "Speed: 2.1ms preprocess, 43.0ms inference, 18.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 4 handbags, 1 chair, 44.0ms\n",
      "Speed: 2.3ms preprocess, 44.0ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 bench, 5 handbags, 1 chair, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 bench, 7 handbags, 1 chair, 44.0ms\n",
      "Speed: 2.0ms preprocess, 44.0ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 bench, 6 handbags, 1 chair, 44.3ms\n",
      "Speed: 2.1ms preprocess, 44.3ms inference, 17.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 5 handbags, 1 chair, 44.5ms\n",
      "Speed: 2.1ms preprocess, 44.5ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 22 persons, 5 handbags, 1 chair, 1 cell phone, 44.6ms\n",
      "Speed: 2.0ms preprocess, 44.6ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 4 handbags, 1 chair, 43.2ms\n",
      "Speed: 2.2ms preprocess, 43.2ms inference, 18.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 4 handbags, 1 chair, 43.4ms\n",
      "Speed: 2.6ms preprocess, 43.4ms inference, 17.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 4 handbags, 1 chair, 43.3ms\n",
      "Speed: 2.0ms preprocess, 43.3ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 4 handbags, 1 chair, 43.5ms\n",
      "Speed: 2.2ms preprocess, 43.5ms inference, 17.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 4 handbags, 1 chair, 43.1ms\n",
      "Speed: 2.1ms preprocess, 43.1ms inference, 18.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 1 bench, 5 handbags, 1 chair, 42.7ms\n",
      "Speed: 2.2ms preprocess, 42.7ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people_bbox: [18, 17, 16, 17, 18, 18, 16, 18, 16, 17, 17, 18, 20, 19, 20, 19, 18, 18, 19, 17, 17, 17, 15, 15, 15, 17, 16, 16, 17, 18, 18, 19, 19, 20, 20, 21, 18, 18, 19, 18, 20, 20, 19, 18, 19, 20, 21, 21, 21, 20, 20, 20, 19, 19, 19, 20, 20, 19, 20, 19, 19, 20, 20, 19, 19, 20, 20, 19, 20, 20, 19, 17, 17, 18, 19, 19, 20, 19, 19, 19, 19, 18, 18, 18, 18, 19, 20, 19, 20, 17, 20, 21, 21, 21, 22, 22, 18, 20, 19, 19, 19, 18]\n",
      "Last People: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 18 persons, 2 benchs, 5 handbags, 1 chair, 59.9ms\n",
      "Speed: 4.4ms preprocess, 59.9ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 benchs, 5 handbags, 1 chair, 42.1ms\n",
      "Speed: 2.8ms preprocess, 42.1ms inference, 13.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 benchs, 4 handbags, 1 chair, 51.6ms\n",
      "Speed: 2.9ms preprocess, 51.6ms inference, 20.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 benchs, 4 handbags, 1 chair, 54.8ms\n",
      "Speed: 3.7ms preprocess, 54.8ms inference, 19.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 18 persons, 2 benchs, 3 handbags, 1 chair, 47.8ms\n",
      "Speed: 3.1ms preprocess, 47.8ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 benchs, 3 handbags, 1 chair, 44.1ms\n",
      "Speed: 2.5ms preprocess, 44.1ms inference, 16.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 benchs, 4 handbags, 1 chair, 43.2ms\n",
      "Speed: 2.4ms preprocess, 43.2ms inference, 16.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 benchs, 2 handbags, 1 chair, 42.2ms\n",
      "Speed: 2.1ms preprocess, 42.2ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 17 persons, 2 benchs, 3 handbags, 1 chair, 1 cell phone, 42.8ms\n",
      "Speed: 2.2ms preprocess, 42.8ms inference, 17.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 1 bench, 3 handbags, 1 chair, 1 cell phone, 43.4ms\n",
      "Speed: 2.3ms preprocess, 43.4ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 2 handbags, 1 chair, 1 cell phone, 44.7ms\n",
      "Speed: 2.3ms preprocess, 44.7ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 2 handbags, 1 chair, 1 cell phone, 43.5ms\n",
      "Speed: 2.3ms preprocess, 43.5ms inference, 18.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 benchs, 2 handbags, 1 chair, 1 cell phone, 44.4ms\n",
      "Speed: 2.2ms preprocess, 44.4ms inference, 19.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 2 benchs, 3 handbags, 1 chair, 1 cell phone, 43.9ms\n",
      "Speed: 2.2ms preprocess, 43.9ms inference, 19.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 bench, 2 handbags, 1 chair, 1 cell phone, 43.7ms\n",
      "Speed: 2.2ms preprocess, 43.7ms inference, 17.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 3 handbags, 1 chair, 2 cell phones, 43.7ms\n",
      "Speed: 2.2ms preprocess, 43.7ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 benchs, 3 handbags, 1 chair, 2 cell phones, 43.5ms\n",
      "Speed: 2.2ms preprocess, 43.5ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 bench, 2 handbags, 1 chair, 2 cell phones, 43.5ms\n",
      "Speed: 2.1ms preprocess, 43.5ms inference, 18.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 1 train, 1 bench, 3 handbags, 1 chair, 2 cell phones, 43.9ms\n",
      "Speed: 2.2ms preprocess, 43.9ms inference, 17.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 20 persons, 1 train, 2 benchs, 3 handbags, 1 chair, 2 cell phones, 43.5ms\n",
      "Speed: 2.4ms preprocess, 43.5ms inference, 18.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 benchs, 2 handbags, 1 chair, 2 cell phones, 43.6ms\n",
      "Speed: 2.3ms preprocess, 43.6ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 19 persons, 2 benchs, 2 handbags, 1 chair, 2 cell phones, 43.4ms\n",
      "Speed: 2.4ms preprocess, 43.4ms inference, 17.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 2 benchs, 3 handbags, 1 chair, 2 cell phones, 43.9ms\n",
      "Speed: 2.1ms preprocess, 43.9ms inference, 18.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 21 persons, 2 benchs, 5 handbags, 1 chair, 2 cell phones, 44.2ms\n",
      "Speed: 2.2ms preprocess, 44.2ms inference, 18.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "people_bbox: [18, 17, 16, 17, 18, 18, 16, 18, 16, 17, 17, 18, 20, 19, 20, 19, 18, 18, 19, 17, 17, 17, 15, 15, 15, 17, 16, 16, 17, 18, 18, 19, 19, 20, 20, 21, 18, 18, 19, 18, 20, 20, 19, 18, 19, 20, 21, 21, 21, 20, 20, 20, 19, 19, 19, 20, 20, 19, 20, 19, 19, 20, 20, 19, 19, 20, 20, 19, 20, 20, 19, 17, 17, 18, 19, 19, 20, 19, 19, 19, 19, 18, 18, 18, 18, 19, 20, 19, 20, 17, 20, 21, 21, 21, 22, 22, 18, 20, 19, 19, 19, 18, 18, 18, 17, 17, 18, 19, 19, 19, 17, 21, 19, 20, 19, 21, 20, 19, 19, 19, 19, 20, 19, 19, 21, 21]\n",
      "Last People: 21\n",
      "people_bbox: [18, 17, 16, 17, 18, 18, 16, 18, 16, 17, 17, 18, 20, 19, 20, 19, 18, 18, 19, 17, 17, 17, 15, 15, 15, 17, 16, 16, 17, 18, 18, 19, 19, 20, 20, 21, 18, 18, 19, 18, 20, 20, 19, 18, 19, 20, 21, 21, 21, 20, 20, 20, 19, 19, 19, 20, 20, 19, 20, 19, 19, 20, 20, 19, 19, 20, 20, 19, 20, 20, 19, 17, 17, 18, 19, 19, 20, 19, 19, 19, 19, 18, 18, 18, 18, 19, 20, 19, 20, 17, 20, 21, 21, 21, 22, 22, 18, 20, 19, 19, 19, 18, 18, 18, 17, 17, 18, 19, 19, 19, 17, 21, 19, 20, 19, 21, 20, 19, 19, 19, 19, 20, 19, 19, 21, 21]\n",
      "Last People: 21\n",
      "people_bbox: [18, 17, 16, 17, 18, 18, 16, 18, 16, 17, 17, 18, 20, 19, 20, 19, 18, 18, 19, 17, 17, 17, 15, 15, 15, 17, 16, 16, 17, 18, 18, 19, 19, 20, 20, 21, 18, 18, 19, 18, 20, 20, 19, 18, 19, 20, 21, 21, 21, 20, 20, 20, 19, 19, 19, 20, 20, 19, 20, 19, 19, 20, 20, 19, 19, 20, 20, 19, 20, 20, 19, 17, 17, 18, 19, 19, 20, 19, 19, 19, 19, 18, 18, 18, 18, 19, 20, 19, 20, 17, 20, 21, 21, 21, 22, 22, 18, 20, 19, 19, 19, 18, 18, 18, 17, 17, 18, 19, 19, 19, 17, 21, 19, 20, 19, 21, 20, 19, 19, 19, 19, 20, 19, 19, 21, 21]\n",
      "Last People: 21\n"
     ]
    }
   ],
   "source": [
    "\n",
    "people_bbox = []  # 감지된 사람의 수를 저장할 리스트\n",
    "paused = False  # 동영상 일시 정지 여부를 저장하는 변수\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "            \n",
    "        results = model(frame, device=\"mps\")\n",
    "        result = results[0]\n",
    "        bboxes = np.array(result.boxes.xyxy.cpu(), dtype=\"int\")\n",
    "        classes = np.array(result.boxes.cls.cpu(), dtype=\"int\")\n",
    "        \n",
    "        persons_mask = classes == 0  # 0은 persons 클래스의 인덱스\n",
    "        frame_persons_bboxes = bboxes[persons_mask]\n",
    "        \n",
    "        num_persons = frame_persons_bboxes.shape[0]  # 현재 프레임에서 감지된 사람의 수\n",
    "        people_bbox.append(num_persons)\n",
    "        \n",
    "        for bbox in frame_persons_bboxes:\n",
    "            (x, y, x2, y2) = bbox\n",
    "            cv2.rectangle(frame, (x, y), (x2, y2), (0, 0, 225), 2)\n",
    "            cv2.putText(frame, \"Person\", (x, y-5), cv2.FONT_HERSHEY_PLAIN, 2, (0, 0, 225), 2)\n",
    "        \n",
    "        cv2.imshow(\"Img\", frame)\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    \n",
    "    if key == 27:  # ESC 키를 누르면 동영상 일시 정지/재생\n",
    "        paused = not paused\n",
    "        print(\"people_bbox:\", people_bbox)  # 각 프레임에서 감지된 사람의 수를 출력\n",
    "        last_people = people_bbox[-1]\n",
    "        print(\"Last People:\", last_people)  # 마지막 프레임에서 감지된 사람의 수 출력\n",
    "    elif paused and key != -1:  # 정지 상태에서 다른 키를 누르면 다시 재생\n",
    "        paused = False\n",
    "    \n",
    "    if key == 27 and not paused:  # ESC 키를 누르면서 동시에 재생 중이면 종료\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"people_bbox:\", people_bbox)  # 각 프레임에서 감지된 사람의 수를 출력\n",
    "last_people = people_bbox[-1]\n",
    "print(\"Last People:\", last_people)  # 마지막 프레임에서 감지된 사람의 수 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942f139",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(persons_bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66745de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter3.10",
   "language": "python",
   "name": "jupyter3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
